{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Creating an environenment an installing all the required libraries required to work with.\n",
        "\n"
      ],
      "metadata": {
        "id": "VgFNhq8ReAp_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZP_htUwa22WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98cccf68-6e38-4d40-820f-bbd24e4c52bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo -e 'GOOGLE_API_KEY=AIzaSyCVoRGelyUI5W-2JtP5HWii5rln52FW0Xw' > .env"
      ],
      "metadata": {
        "id": "qaF_YBD73cxh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqxSR_rf4FNn",
        "outputId": "ab9665ad-d069-4ac2-ee68-be5ada2f0f39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  .config\tdrive  .env  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2900thxq4Im6",
        "outputId": "9cf84878-edf1-4203-f106-6745d45e2f12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import HTML\n",
        "from IPython.display import Markdown\n",
        "\n",
        "import textwrap\n",
        "\n",
        "def to_markdown(text):\n",
        "    text=text.replace('.',' *')\n",
        "    return Markdown(textwrap.indent(text,'>',predicate=lambda _:True))"
      ],
      "metadata": {
        "id": "IWVRBEyG4OsY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Google Generative AI and Langchain, we will work with Gemini API"
      ],
      "metadata": {
        "id": "CmttT6vcefmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "19OKJM-a4TKX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "T0iUO0e25Q9v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n",
        "!pip install PyPDF2\n",
        "!pip install pypdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hKzvuQWSSdS",
        "outputId": "2251bb44-e54e-4ee1-fbc3-0f1f810a99c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40702 sha256=a29649a9ab578c318b572d843fe72efe80ec3acbca3c212c825b55d544411ad0\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsaxfatMQxb-",
        "outputId": "a4355351-d5c6-4399-d0c5-eb012254f0cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.36 (from langchain)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.50)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.5 langchain-0.1.17 langchain-community-0.0.36 langchain-text-splitters-0.0.1 marshmallow-3.21.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n"
      ],
      "metadata": {
        "id": "VNyMKr0nTtoX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-auth"
      ],
      "metadata": {
        "id": "Hv3v8UkLvGcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7be66b-cc74-4610-f250-3a286fedf971"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNUh6Sa5_0ez",
        "outputId": "bb87d4b0-5221-4665-8577-451c28587ca0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.5.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.45 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.1.50)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.23.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain_google_genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain_google_genai) (0.1.54)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain_google_genai) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.45->langchain_google_genai) (8.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.45->langchain_google_genai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain_google_genai) (3.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain_google_genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.18.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain_google_genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain_google_genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain_google_genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.45->langchain_google_genai) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t3sBd65qw-mW",
        "outputId": "a8ec9602-21c3-4e6b-ea12-4ec29a6fc09e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.1.0-py3-none-any.whl (8.5 kB)\n",
            "Collecting chromadb<0.5.0,>=0.4.0 (from langchain-chroma)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<1,>=0.95.2 (from langchain-chroma)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.1.50)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (1.25.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (2.7.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (4.11.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (4.66.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.63.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.5.0,>=0.4.0->langchain-chroma) (3.10.3)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading fastapi_cli-0.0.2-py3-none-any.whl (9.1 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (3.1.3)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma) (0.1.54)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.40->langchain-chroma) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.0->langchain-chroma) (2.0.1)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain-chroma) (3.7)\n",
            "Collecting typer>=0.9.0 (from chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain-chroma) (2.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.40->langchain-chroma) (2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.0->langchain-chroma) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.0->langchain-chroma) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb<0.5.0,>=0.4.0->langchain-chroma) (3.3.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma) (0.20.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain-chroma) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.0->langchain-chroma) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (3.18.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (2.16.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.0->langchain-chroma) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=98f21988881fd017bc3bb2ff83339e470d7e75172a36ad542aa789b42fcf398a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, ujson, shellingham, python-multipart, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, h11, dnspython, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpcore, email_validator, coloredlogs, typer, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, fastapi-cli, fastapi, chromadb, langchain-chroma\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.0.0 kubernetes-29.0.0 langchain-chroma-0.1.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.5.0 pypika-0.48.9 python-multipart-0.0.9 shellingham-1.5.4 starlette-0.37.2 typer-0.12.3 ujson-5.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "4c1c051f40014818bf652d5b922e9101"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "jcpH2pD35w1D"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned, we will work with Gemini API"
      ],
      "metadata": {
        "id": "j8M3JZGMevOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)"
      ],
      "metadata": {
        "id": "M-nn1OS2_za1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "NiVCyIIkVUB4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting Google Drive to access the files"
      ],
      "metadata": {
        "id": "At6-FMnXe7UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F_ao-D44rdS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9befabab-8403-45af-8ad6-bd1587d4abe0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n"
      ],
      "metadata": {
        "id": "MLuX-y8vsIBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93dc5926-59e0-43f0-c8b9-102a5c7f88af"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_apple = 'https://drive.google.com/drive/u/0/folders/1G1wUSZPYJ2s-SLEynKhHyZ2kjpu-Sjwd'\n",
        "# This is the folder for apple_filings_pdf, you can download this and upload this in collab for further steps, this can be done as a substitute if the below code is not working"
      ],
      "metadata": {
        "id": "vJl7QT09sM84"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path_msft = 'https://drive.google.com/drive/folders/1Ynn-fSwOhgpWhHMjGT6_z4SFnBTAhT3K?usp=sharing'\n",
        "# This is the folder for microsoft_filings_pdf, you can download this and upload this in collab for further steps, this can be done as a substitute if the below code is not working"
      ],
      "metadata": {
        "id": "VELJo1UhGr1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicating all the files from the Google Drive to the sample_data directory in Google Collab for making it easy to work with"
      ],
      "metadata": {
        "id": "W0-CNLcAe_ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Path to the folder you want to copy (assuming it's already mounted)\n",
        "source_folder_path = '/content/drive/MyDrive/apple_filings_pdf'  # Adjust the path as needed\n",
        "\n",
        "# Path to the destination folder (sample_data folder in Colab)\n",
        "destination_folder_path = '/content/sample_data'  # Adjust the path as needed\n",
        "\n",
        "# Check if the destination folder exists, and create it if it doesn't\n",
        "if not os.path.exists(destination_folder_path):\n",
        "    os.makedirs(destination_folder_path)\n",
        "\n",
        "# Copy the entire folder and its contents\n",
        "shutil.copytree(source_folder_path, os.path.join(destination_folder_path, os.path.basename(source_folder_path)))\n",
        "\n",
        "print(\"Folder copied successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwYr5sQZ3UwL",
        "outputId": "4a27871d-0dfb-4f4a-d996-982c0aa006c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder copied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Path to the folder you want to copy (assuming it's already mounted)\n",
        "source_folder_path = '/content/drive/MyDrive/microsoft_filings_pdf'  # Adjust the path as needed\n",
        "\n",
        "# Path to the destination folder (sample_data folder in Colab)\n",
        "destination_folder_path = '/content/sample_data'  # Adjust the path as needed\n",
        "\n",
        "# Check if the destination folder exists, and create it if it doesn't\n",
        "if not os.path.exists(destination_folder_path):\n",
        "    os.makedirs(destination_folder_path)\n",
        "\n",
        "# Copy the entire folder and its contents\n",
        "shutil.copytree(source_folder_path, os.path.join(destination_folder_path, os.path.basename(source_folder_path)))\n",
        "\n",
        "print(\"Folder copied successfully.\")\n"
      ],
      "metadata": {
        "id": "Yv2OagJX3gv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0144cf57-6a96-4b1b-d54f-ab2b7a66da23"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder copied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "offzcPZGKCsA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n"
      ],
      "metadata": {
        "id": "vQllxwiYh8j7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Y1dF9sLmeWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the pdf files to take as the training data for the llm model, Gemini API has a limit of 1,000,000 letters/tokens, hence we can only use 3-4 years of filings at once, the range loop can be adjusted according to the years on which analysis is to be performed, we have taken 2020 to 2023 as our data period/range."
      ],
      "metadata": {
        "id": "Yud6-aOXmfPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pages=[]\n",
        "for year in range(2020,2024):\n",
        "  pdf_loader= PyPDFLoader(f\"/content/sample_data/apple_filings_pdf/apple_{year}.pdf\")\n",
        "  pages1=pdf_loader.load_and_split()\n",
        "  pages=pages+pages1\n",
        "print(pages[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDAMs-slQkfc",
        "outputId": "5ba6842c-d20e-4d10-d160-fdf1ca07cafd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aapl-20200926 \n",
            " \n",
            " \n",
            " \n",
            "UNITED STATES \n",
            "SECURITIES AND EXCHANGE COMMISSION \n",
            "Washington, D.C. 20549 \n",
            " \n",
            " \n",
            "FORM 10-K \n",
            " \n",
            " \n",
            "(Mark One) \n",
            "☒ ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES \n",
            "EXCHANGE ACT OF 1934 \n",
            "For the fiscal year ended September 26, 2020 \n",
            "or \n",
            "☐ TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES \n",
            "EXCHANGE ACT OF 1934 \n",
            "For the transition period from              to             . \n",
            "Commission File Number: 001-36743 \n",
            " \n",
            " \n",
            "Apple Inc. \n",
            "(Exact name of Registrant as specified in its charter) \n",
            " \n",
            " \n",
            " \n",
            "California | 94-2404110  \n",
            "(State or other jurisdictionof incorporation or organization) | (I.R.S. \n",
            "Employer Identification No.) \n",
            "One Apple Park Way |  \n",
            "Cupertino, California | 95014  \n",
            "(Address of principal executive offices) | (Zip Code)  \n",
            " \n",
            "(408) 996-1010 \n",
            "(Registrant ’s telephone number, including area code) \n",
            " \n",
            " \n",
            "Securities registered pursuant to Section 12(b) of the Act: \n",
            " \n",
            "Title of each class | Trading symbol(s) | Name of each exchange on which \n",
            "registered \n",
            "Common Stock, $0.00001 par value per share | AAPL | The Nasdaq Stock \n",
            "Market LLC  \n",
            "1.000% Notes due 2022 | — | The Nasdaq Stock Market LLC  \n",
            "1.375% Notes due 2024 | — | The Nasdaq Stock Market LLC  \n",
            "0.000% Notes due 2025 | — | The Nasdaq Stock Market LLC  \n",
            "0.875% Notes due 2025 | — | The Nasdaq Stock Market LLC  \n",
            "1.625% Notes due 2026 | — | The Nasdaq Stock Market LLC  \n",
            "2.000% Notes due 2027 | — | The Nasdaq Stock Market LLC  \n",
            "1.375% Notes due 2029 | — | The Nasdaq Stock Market LLC  \n",
            "3.050% Notes due 2029 | — | The Nasdaq Stock Market LLC  \n",
            "0.500% Notes due 2031 | — | The Nasdaq Stock Market LLC  \n",
            "3.600% Notes due 2042 | — | The Nasdaq Stock Market LLC  \n",
            " \n",
            "Securities registered pursuant to Section 12(g) of the Act: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Do4h96fKOMN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(pdf_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "9iOHCr9zKjsU",
        "outputId": "77696083-519c-42aa-9e8e-d34c7880129e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_community.document_loaders.pdf.PyPDFLoader"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_community.document_loaders.pdf.PyPDFLoader</b><br/>def __init__(file_path: str, password: Optional[Union[str, bytes]]=None, headers: Optional[Dict]=None, extract_images: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/pdf.py</a>Load PDF using pypdf into list of documents.\n",
              "\n",
              "Loader chunks by page and stores page numbers in metadata.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 162);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This context will be used to fine-tune our model"
      ],
      "metadata": {
        "id": "7Ad95HKTrGz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context=\"\\n\".join(str(p.page_content) for p in pages[0:])\n",
        "print(len(context))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJhuQ1xINrIg",
        "outputId": "c76a2606-71e6-4499-ba02-e5165100bd58"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1175008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c3QyNK2h249",
        "outputId": "cc169f55-5653-4c2e-e9c2-71d9eeb8948c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #print(context)"
      ],
      "metadata": {
        "id": "tEg3kgObzM4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our prompt"
      ],
      "metadata": {
        "id": "LVAz8Xm5nS5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"Answer the question based on context and your analysis of the question using the provided documents, you can also use external sources but keep the answer relevent to the question asked. If you can not answer,say \"Sorry I don't know\"\\n\\n\n",
        "                    Context: \\n {context}?\\n\n",
        "                    Question:\\n {question}\\n\n",
        "                    Answer:\n",
        "                    \"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\",\"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Bzb3XHqjDMVH"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Gemini-pro model for our llm, temperature is set to 0, to provide the model with creativity in generating answers. if temperature is 1, this would take away the creativity of the model, this range can lie between 0 and 1"
      ],
      "metadata": {
        "id": "DYq48cHVnZEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)\n",
        "stuff_chain = load_qa_chain(model,chain_type=\"stuff\",prompt=prompt)"
      ],
      "metadata": {
        "id": "UfCNkOZvM1cO"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Give me summary with supporting numbers over the years, using them give me insights which can help me invest in the company\"\n",
        "question2 = \"See the financial balancesheet of years 2021 and 2023 and compare them?\"\n",
        "question3 = \"Tell me about legal cases and lawsuits against the company with some cases/examples \""
      ],
      "metadata": {
        "id": "lRwEorRrlbQY"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting the data into trainable data for our model"
      ],
      "metadata": {
        "id": "nRtvvGMDrRbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=RecursiveCharacterTextSplitter(\n",
        "    chunk_size=20000,\n",
        "    chunk_overlap=2000,\n",
        ")\n",
        "context=\"\\n\".join(str(p.page_content) for p in pages)\n",
        "texts=text_splitter.split_text(context)"
      ],
      "metadata": {
        "id": "by_-IZeoh-JD"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(texts[0])"
      ],
      "metadata": {
        "id": "eOV0-cN50M2L"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", temperature=0)"
      ],
      "metadata": {
        "id": "eP6f83myh-Fg"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index=Chroma.from_texts(texts,embeddings).as_retriever()"
      ],
      "metadata": {
        "id": "2W93epa-h-Cv"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement a RAG model, in the below code we will retrive only those pages which are relevent to our question and get answers accordingly. This will reduce the time complexity and computational complexity and increase efficiency."
      ],
      "metadata": {
        "id": "c7Yu9iAErh4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = vector_index.get_relevant_documents(question)\n",
        "docs2 = vector_index.get_relevant_documents(question2)\n",
        "docs3 = vector_index.get_relevant_documents(question3)\n",
        "\n"
      ],
      "metadata": {
        "id": "cYEn1eNdh95i"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get answers based on the questions asked and relevent documents for our answers."
      ],
      "metadata": {
        "id": "EMQ133DGr_Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stuff_answer_insights = stuff_chain(\n",
        "    {\"input_documents\": docs, \"question\": question}, return_only_outputs=True\n",
        ")\n",
        "stuff_answer_financials = stuff_chain(\n",
        "    {\"input_documents\": docs2, \"question\": question2}, return_only_outputs=True\n",
        ")\n",
        "stuff_answer_legal = stuff_chain(\n",
        "    {\"input_documents\": docs3, \"question\": question3}, return_only_outputs=True\n",
        ")"
      ],
      "metadata": {
        "id": "tVttnERWjCjb"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stuff_answer_insights)\n",
        "print(stuff_answer_financials)\n",
        "print(stuff_answer_legal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G_-kg74jHPC",
        "outputId": "68e7b54e-c9ad-4b32-d36c-ed99d7e3ed28"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'output_text': \"Sorry I don't know\"}\n",
            "{'output_text': \"Sorry I can't answer this question. The provided context does not include the financial balance sheet for the year 2023.\"}\n",
            "{'output_text': \"The company is subject to a variety of claims and lawsuits that arise from time to time in the ordinary course of business. These claims may arise from a wide variety of business practices and initiatives, including major new product releases such as Windows, AI services, significant business transactions, warranty or product claims, employment practices, and regulation. Adverse outcomes in some or all of these claims may result in significant monetary damages or injunctive relief that could adversely affect the company's ability to conduct its business.\\n\\nOne example of a legal case against the company is the consolidated cases moved to exclude the plaintiffs' expert evidence of general causation on the basis of flawed scientific methodologies. In 2014, the trial court granted in part and denied in part the defendants' motion to exclude the plaintiffs' general causation experts. The defendants filed an interlocutory appeal to the District of Columbia Court of Appeals challenging the standard for evaluating expert scientific evidence. In October 2016, the Court of Appeals issued its decision adopting the standard advocated by the defendants and remanding the cases to the trial court for further proceedings under that standard. The plaintiffs have filed supplemental expert evidence, portions of which the defendants have moved to strike. In August 2018, the trial court issued an order striking portions of the plaintiffs' expert reports. A hearing on general causation is scheduled for January and February of 2022.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will convert these answers into txt files which will be then used as a backend data for the web app which be deployed using streamlit."
      ],
      "metadata": {
        "id": "pTq8noa8sbez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Convert dictionaries to strings\n",
        "stuff_answer_insights_str = str(stuff_answer_insights)\n",
        "stuff_answer_financials_str = str(stuff_answer_financials)\n",
        "stuff_answer_legal_str = str(stuff_answer_legal)\n",
        "\n",
        "# Define the folder name and create the folder\n",
        "folder_name = \"apple_data\"\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "# Define the file names with the folder path\n",
        "file_names = [os.path.join(folder_name, \"apple_insights.txt\"),\n",
        "              os.path.join(folder_name, \"apple_financials.txt\"),\n",
        "              os.path.join(folder_name, \"apple_legal.txt\")]\n",
        "\n",
        "# Define the contents list\n",
        "contents = [stuff_answer_insights_str,\n",
        "            stuff_answer_financials_str,\n",
        "            stuff_answer_legal_str]\n",
        "\n",
        "# Write each content to its respective file\n",
        "for file_name, content in zip(file_names, contents):\n",
        "    with open(file_name, \"w\") as file:\n",
        "        file.write(content)\n",
        "\n",
        "# Create a zip file containing the folder\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(folder_name, 'zip', folder_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Xjg7KYj8WyPE",
        "outputId": "48031121-97ae-4f79-81a1-76ac773dbb99"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/apple_data.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We did this whole process for apple stocks, now we will perform the same for microsoft filings."
      ],
      "metadata": {
        "id": "sW7vN2DJuKAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pages_msft=[]\n",
        "for year in range(2022,2024):\n",
        "  pdf_loader= PyPDFLoader(f\"/content/sample_data/microsoft_filings_pdf/microsoft_{year}.pdf\")\n",
        "  pages1=pdf_loader.load_and_split()\n",
        "  pages_msft=pages+pages1\n",
        "#print(pages_msft[0].page_content)"
      ],
      "metadata": {
        "id": "AtOAwzGOsyTT"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x2iQNcCcd_En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_msft=\"\\n\".join(str(p.page_content) for p in pages_msft)\n",
        "#print((context_msft))"
      ],
      "metadata": {
        "id": "pYiNb8GWtCBi"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_msft = \"\"\"Answer the question based on context and your analysis of the question, you can also use external sources but keep the answer relevent to the question asked. If you can not answer,say \"Sorry I don't know\"\\n\\n\n",
        "                    Context: \\n {context}?\\n\n",
        "                    Question:\\n {question}\\n\n",
        "                    Answer:\n",
        "                    \"\"\"\n",
        "prompt_msft = PromptTemplate(\n",
        "    template=prompt_template_msft, input_variables=[\"context\",\"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "KbUxEU9wtXOl"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter_msft=RecursiveCharacterTextSplitter(\n",
        "    chunk_size=20000,\n",
        "    chunk_overlap=2000,\n",
        ")\n",
        "context_msft=\"\\n\".join(str(p.page_content) for p in pages_msft)\n",
        "texts_msft=text_splitter_msft.split_text(context_msft)"
      ],
      "metadata": {
        "id": "52pV-2YktlnM"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index_msft=Chroma.from_texts(texts_msft,embeddings).as_retriever()"
      ],
      "metadata": {
        "id": "z6-AV-j5t2QN"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_msft = vector_index_msft.get_relevant_documents(question)\n",
        "docs2_msft = vector_index_msft.get_relevant_documents(question2)\n",
        "docs3_msft = vector_index_msft.get_relevant_documents(question3)\n"
      ],
      "metadata": {
        "id": "BFu2cXMKt6v9"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stuff_answer_msft_insights = stuff_chain(\n",
        "    {\"input_documents\": docs_msft, \"question\": question}, return_only_outputs=True\n",
        ")\n",
        "stuff_answer_msft_financials = stuff_chain(\n",
        "    {\"input_documents\": docs2_msft, \"question\": question2}, return_only_outputs=True\n",
        ")\n",
        "stuff_answer_msft_legal = stuff_chain(\n",
        "    {\"input_documents\": docs3_msft, \"question\": question3}, return_only_outputs=True\n",
        ")"
      ],
      "metadata": {
        "id": "6j_0iVCIt94S"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GIve me some insights about the company and its pros and cons which can help me deciding to invest in this comapny or not. Also give me some prediction about the future of the company"
      ],
      "metadata": {
        "id": "N95O2R-WKIpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(stuff_answer_msft_insights)\n",
        "print(stuff_answer_msft_financials)\n",
        "print(stuff_answer_msft_legal)"
      ],
      "metadata": {
        "id": "hsW12leSuOZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a288b1-0528-41ef-92a0-17c87ec42175"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'output_text': \"**Revenue Growth:**\\n\\n* Revenue has grown significantly over the past three years, from $168,088 million in 2021 to $211,915 million in 2023, representing an increase of 25.5%.\\n* This growth has been driven by strong demand for the company's cloud-based solutions, such as Office 365, Azure, and Dynamics 365.\\n\\n**Profitability:**\\n\\n* Net income has also increased over the past three years, from $61,271 million in 2021 to $72,361 million in 2023, representing an increase of 18.1%.\\n* This increase in profitability has been driven by the company's focus on cost optimization and its ability to generate revenue from high-margin cloud services.\\n\\n**Financial Strength:**\\n\\n* The company has a strong financial position, with cash and cash equivalents of $34,704 million as of June 30, 2023.\\n* The company also has a low level of debt, with total liabilities of $205,753 million as of June 30, 2023.\\n\\n**Valuation:**\\n\\n* The company's stock price has performed well over the past three years, increasing from $285.26 on June 30, 2021, to $333.19 on June 30, 2023.\\n* The company's current price-to-earnings (P/E) ratio is 26.7, which is higher than the average P/E ratio for the technology sector.\\n\\n**Risks:**\\n\\n* The company faces competition from other technology companies, such as Amazon, Google, and Apple.\\n* The company's revenue is heavily dependent on the cloud computing market, which is subject to rapid technological change.\\n* The company's operations are global, which exposes it to risks related to currency fluctuations and geopolitical events.\\n\\n**Overall:**\\n\\nBased on the summary, Microsoft Corporation appears to be a financially strong and growing company with a strong track record of profitability. The company's focus on cloud-based solutions and its ability to generate revenue from high-margin services make it an attractive investment opportunity. However, investors should be aware of the risks associated with investing in the technology sector and should carefully consider the company's valuation before making an investment decision.\"}\n",
            "{'output_text': \"**Assets**\\n\\n* **Current assets:**\\n    * Cash and cash equivalents: Increased from $13,931 million in 2021 to $34,704 million in 2023.\\n    * Short-term investments: Decreased from $90,826 million in 2021 to $76,558 million in 2023.\\n    * Accounts receivable, net: Increased from $44,261 million in 2021 to $48,688 million in 2023.\\n    * Inventories: Decreased from $3,742 million in 2021 to $2,500 million in 2023.\\n    * Other current assets: Increased from $16,924 million in 2021 to $21,807 million in 2023.\\n* **Total current assets:** Increased from $169,684 million in 2021 to $184,257 million in 2023.\\n* **Property and equipment, net:** Increased from $74,398 million in 2021 to $95,641 million in 2023.\\n* **Operating lease right-of-use assets:** Increased from $13,148 million in 2021 to $14,346 million in 2023.\\n* **Equity investments:** Increased from $6,891 million in 2021 to $9,879 million in 2023.\\n* **Goodwill:** Remained relatively stable at $67,886 million in 2023 compared to $67,524 million in 2021.\\n* **Intangible assets, net:** Decreased from $11,298 million in 2021 to $9,366 million in 2023.\\n* **Other long-term assets:** Increased from $21,897 million in 2021 to $30,601 million in 2023.\\n\\n**Liabilities**\\n\\n* **Current liabilities:**\\n    * Accounts payable: Decreased from $19,000 million in 2021 to $18,095 million in 2023.\\n    * Current portion of long-term debt: Increased from $2,749 million in 2021 to $5,247 million in 2023.\\n    * Accrued compensation: Increased from $10,661 million in 2021 to $11,009 million in 2023.\\n    * Short-term income taxes: Increased from $4,067 million in 2021 to $4,152 million in 2023.\\n    * Short-term unearned revenue: Increased from $45,538 million in 2021 to $50,901 million in 2023.\\n    * Other current liabilities: Increased from $13,067 million in 2021 to $14,745 million in 2023.\\n* **Total current liabilities:** Increased from $95,082 million in 2021 to $104,149 million in 2023.\\n* **Long-term debt:** Decreased from $47,032 million in 2021 to $41,990 million in 2023.\\n* **Long-term income taxes:** Decreased from $26,069 million in 2021 to $25,560 million in 2023.\\n* **Long-term unearned revenue:** Remained relatively stable at $2,912 million in 2023 compared to $2,870 million in 2021.\\n* **Deferred income taxes:** Increased from $230 million in 2021 to $433 million in 2023.\\n* **Operating lease liabilities:** Increased from $11,489 million in 2021 to $12,728 million in 2023.\\n* **Other long-term liabilities:** Increased from $15,526 million in 2021 to $17,981 million in 2023.\\n\\n**Stockholders' Equity**\\n\\n* **Common stock and paid-in capital:** Increased from $86,939 million in 2021 to $93,718 million in 2023.\\n* **Retained earnings:** Increased from $84,281 million in 2021 to $118,848 million in 2023.\\n* **Accumulated other comprehensive income (loss):** Decreased from $4,678 million in 2021 to $6,343 million in 2023.\\n* **Total stockholders' equity:** Increased from $166,542 million in 2021 to $206,223 million in 2023.\"}\n",
            "{'output_text': 'The Company is vigorously defending infringement actions in courts in several U.S. jurisdictions, as well as internationally in various countries. The plaintiffs in these actions frequently seek injunctions and substantial damages. \\nFor example, the Company is the subject of investigations in Europe and other jurisdictions relating to App Store terms and conditions. If such investigations result in adverse findings against the Company, the Company could be exposed to significant fines and may be required to make changes to its App Store business, all of which could materially adversely affect the Company’s business, results of operations and financial condition.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Convert dictionaries to strings\n",
        "stuff_answer_msft_insights_str = str(stuff_answer_msft_insights)\n",
        "stuff_answer_msft_financials_str = str(stuff_answer_msft_financials)\n",
        "stuff_answer_msft_legal_str = str(stuff_answer_msft_legal)\n",
        "\n",
        "# Define the folder name and create the folder\n",
        "folder_name = \"msft_data\"\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "\n",
        "# Define the file names with the folder path\n",
        "file_names = [os.path.join(folder_name, \"msft_insights.txt\"),\n",
        "              os.path.join(folder_name, \"msft_financials.txt\"),\n",
        "              os.path.join(folder_name, \"msft_legal.txt\")]\n",
        "\n",
        "# Define the contents list\n",
        "contents = [stuff_answer_msft_insights_str,\n",
        "            stuff_answer_msft_financials_str,\n",
        "            stuff_answer_msft_legal_str]\n",
        "\n",
        "# Write each content to its respective file\n",
        "for file_name, content in zip(file_names, contents):\n",
        "    with open(file_name, \"w\") as file:\n",
        "        file.write(content)\n",
        "\n",
        "# Create a zip file containing the folder\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(folder_name, 'zip', folder_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vtRCKH4dVYdq",
        "outputId": "4cd7ca78-8f3f-4bda-cb7b-572c9ddcdbba"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/msft_data.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import streamlit as st, pandas as pd, numpy as np, yfinance as yf\n",
        "# import plotly.express as px\n",
        "\n",
        "# st.title('Company Insights')\n",
        "# ticker=st.sidebar.text_input('Ticker')\n",
        "# start_date=st.sidebar.date_input('Start Date')\n",
        "# end_date=st.sidebar.date_input('End Date')\n",
        "\n",
        "# # data=yf.download(ticker,start=start_date,end=end_date)\n",
        "# # fig=px.line(data,x = data.index, y = data['Adj Close'], title=ticker)\n",
        "# # st.plotly_chart(fig)\n",
        "\n",
        "# insights, financials, legal = st.tabs([\"Insights\", \"Fundamental Data\", \"Legal\"])\n",
        "\n",
        "# with insights:\n",
        "#   if ticker==\"AAPL\":\n",
        "#     st.write(stuff_answer_insights)\n",
        "#   else:\n",
        "#     st.write(stuff_answer_msft_insights)\n",
        "\n",
        "# with financials:\n",
        "#   if ticker==\"AAPL\":\n",
        "#     st.write(stuff_answer_financials)\n",
        "#   else:\n",
        "#     st.write(stuff_answer_msft_legal)\n",
        "\n",
        "# with legal:\n",
        "#   if ticker==\"AAPL\":\n",
        "#     st.write(stuff_answer_financials)\n",
        "#   else:\n",
        "#     st.write(stuff_answer_msft_legal)"
      ],
      "metadata": {
        "id": "iCyjoBDrcHOo"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NftsgZXOtAj",
        "outputId": "9358b117-3911-46ee-c677-22f7e10fe725"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: llm_in_10k_filings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I1h5V94xRhAU"
      },
      "execution_count": 174,
      "outputs": []
    }
  ]
}